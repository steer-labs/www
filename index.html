<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta name="author" content="Asandei Stefan-Alexandru" />
    <meta name="date" content="02.11.2024" />
    <title>Steer</title>
    <link rel="stylesheet" href="reset.css" />
    <link rel="stylesheet" href="index.css" />
</head>

<body>
    <table class="header">
        <tr>
            <td colspan="2" rowspan="2" class="width-auto">
                <h1 class="title">Steer</h1>
                <span class="subtitle">Efficient autonomous vehicle software</span>
            </td>
            <th>Version</th>
            <td class="width-min">0.1</td>
        </tr>
        <tr class="width-auto">
            <th class="width-min">Source</th>
            <td><a href="https://github.com/stefanasandei/steer" target="_blank">repo</td>
        </tr>
        <tr>
            <!-- <th class="width-min">Author</th>
            <td class="width-auto"><a href="https://asandei.com"><cite>Asandei Stefan-Alexandru</cite></a></td> -->

            <!-- <th class="width-min">License</th>
            <td>Apache 2</td> -->
        </tr>
    </table>

    <h2 id="introduction">Introduction</h2>
    <p>The Transformer architecture has become widely used for all sorts of tasks, such as language, vision, genetics
        and many more.
        I think attention ain't all we need. I also think there isn't a universal architecture we have to find, the
        answer can be in
        the balance. That's why I am looking forward to develop hybrid models, based on attention and state spaces. The
        first
        Steer model is using the Video Mamba architecture, with a focus on performance at inference time.
    </p>
    <p>Why self-driving? it's a hard task, requiring multiple data inputs, local and global temporal awareness, complex
        data relationships. This project does not aim to provide full autonomy, but to test the capabilities of our
        architecture. We also don't have the necessary hardware to train such big models, yet. </p>
    <p>Read more about the research process, model architecture and findings in the tehnical report: <a
            href="report-en.pdf" target="_blank">english</a> and <a href="report-ro.pdf" target="_blank">romanian</a>.
    </p>

    <!-- <h2 id="the-future">The Future</h2>
    <p>more training and scale up</p> -->

    <h2 id="contact">Contact</h2>
    <p>I'm Stefan Asandei, an 11th grade student from Romania. I build open software on <a
            href="https://github.com/stefanasandei" target="_blank">github</a> and write about it on <a
            href="https://asandei.com/blog" target="_blank">my blog</a>.</p>
    <ul>
        <li>Email: <a href="mailto:asandei.stefanel@gmail.com">asandei.stefanel@gmail.com</a></li>
        <li>Website: <a href="https://asandei.com">asandei.com</a></li>
        <li>Discord: <a href="about:blank">@stefanasandei</a></li>
        <li>Twitter: <a href="https://x.com/stefan_asandei" target="_blank">@stefan_asandei</a></li>
    </ul>

    <hr>

    <a href="https://asandei.com" target="_blank">Asandei Stefan-Alexandru</a>
    <p>November 2nd, 2024</p>
</body>

</html>